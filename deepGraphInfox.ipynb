{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import dgl\n",
    "from tqdm import tqdm\n",
    "EPS = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl import DGLGraph\n",
    "from dgl.data import citation_graph as citegrh\n",
    "from dgl.nn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): # layer\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = GraphConv(in_channels, hidden_channels)\n",
    "        self.prelu = nn.PReLU(hidden_channels)\n",
    "\n",
    "    def forward(self, g,feat):\n",
    "        with g.local_scope():\n",
    "            h = self.conv(g, feat)\n",
    "            h = self.prelu(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corruption(x):\n",
    "    return x[torch.randperm(x.size(0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()\n",
    "    features = torch.FloatTensor(data.features)\n",
    "    labels = torch.LongTensor(data.labels)\n",
    "    train_mask = torch.BoolTensor(data.train_mask)\n",
    "    test_mask = torch.BoolTensor(data.test_mask)\n",
    "    g = DGLGraph(data.graph)\n",
    "    return g, features, labels, train_mask, test_mask\n",
    "g, features, labels, train_mask, test_mask = load_cora_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DeepGraphInfomax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGraphInfomax(\n",
       "  (encoder): Encoder(\n",
       "    (conv): GraphConv(in=1433, out=512, normalization=both, activation=None)\n",
       "    (prelu): PReLU(num_parameters=512)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepGraphInfomax(hidden_feats=512,encoder=Encoder(features.shape[1],512),\n",
    "                        summary = lambda z, *args,**kwargs:torch.sigmoid(\n",
    "                            z.mean(dim=0)),\n",
    "                        corruption=corruption)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pos_z, neg_z, summary = model(g, features)\n",
    "    loss = model.loss(pos_z, neg_z, summary)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50/249 [00:13<00:50,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: 0.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100/249 [00:26<00:38,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.3570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 150/249 [00:39<00:28,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Loss: 0.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/249 [00:54<00:14,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [01:08<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range( 1,250)):\n",
    "    loss = train()\n",
    "    if epoch % 50 ==0:\n",
    "        print('Epoch: {:03d}, Loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def test( train_z, train_y, test_z, test_y, solver='lbfgs',\n",
    "         multi_class='auto', *args, **kwargs):\n",
    "    r\"\"\"Evaluates latent space quality via a logistic regression downstream\n",
    "    task.\"\"\"\n",
    "    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n",
    "                             **kwargs).fit(train_z.detach().cpu().numpy(),\n",
    "                                           train_y.detach().cpu().numpy())\n",
    "    return clf.score(test_z.detach().cpu().numpy(),\n",
    "                     test_y.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_latent():\n",
    "    model.eval()\n",
    "    z, _, _ = model(g, features)\n",
    "    acc = test(z[train_mask], labels[train_mask],\n",
    "                     z[test_mask], labels[test_mask], max_iter=150)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_latent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
